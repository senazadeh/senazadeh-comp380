<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <link rel="stylesheet" href="../styles.css">

  <title>Technology and the “Crisis” of Misinformation</title>
</head>

<body>

  <div class="container-fluid">
    <div class="row header">
        <a class="white" href="../index.html"><h1>Technology and the “Crisis” of Misinformation</h1></a>
    </div>
    <div class="row toolbar">
        
    </div>
    <div class="row">
      <div class="col-2 sidebar">
          <ul><br><br>
            <a class="white" href="socialMedia.html"><li>Facebook and Twitter</li></a><br><br>
            <a class="white" href="misinformation.html"><li>Misinformation and Politics</li></a><br><br>
            <a class="white" href="emotionalContagion.html"><li>Echo Chambers and Misinformation</li></a><br><br>
            <a class="white" href="howToSpot.html"><li>How to Spot Misinformation</li></a>
          </ul>        
      </div>
        <div class="col-10 main">
            <h2>Facebook and Twitter</h2><br>

            <h4>Social Media Algorithms</h4>
            <p class="info">When perusing through a feed, a user gets clues from the environment and their peers and translates these signals into decisions, such as a like or comment in agreement. In this case, the current state of social media gives users access to signals from large numbers of people and AI uses these engagement signals for recommendation algorithms, the order you see posts on news feeds, suggesting friends you may know, etc.<br><br>
            Facebook and Twitter both rely on AI algorithms to rank and recommend content to its users. Their goal is to maximize engagement to keep the users on their platform by finding out what people like and ranking it at the top of their feeds. When users interact with misinformation on their feed, the algorithm sees their engagement and recommends more of similar content as well as shows the content to more users. Hence, once a post is shared, even if it contains misinformation, it's easy for it to become widespread and get picked up in articles and news coverage, amplifying its reach.</p>

            <img class="image" width="50%" src="../images/phone.png" alt="Phone">

            <h4>Facebook</h4>
            <p class="info">Studies have incited that the Facebook algorithm has proven to fuel the spread of misinformation more than the spread of reliable and trustworthy information. In a peer reviewed study conducted by researchers at New York University and the Université Grenoble Alpes in France, it was found that from August 2020 to January 2021, “news publishers known for putting out misinformation got six times the amount of likes, shares, and interactions as did trustworthy news sources, such as the World Health Organization.” Misinformation has the greatest chance of getting widespread when it contains content that exploits feelings of superiority, anger, or fear against another group. News publishers or people of any kind can capitalize on these human biases and utilize it to increase engagement by provoking our existing grievances and beliefs in order to increase user interaction. <br><br>
            The platform itself also supports the use of large, private Facebook groups. These groups lead to polarizing environments and interacting with one group leads to suggestions to join a similar group. When misinformation is shared within these private groups to a large number of people, the lack of effective moderation from Facebook allows for the misinformed content to spread even further. </p><br>

            <h4>Twitter</h4>
            <p class="info">Bots, trolls, and fake accounts are also prevalent on Twitter and their heavy online presence contributes to the proliferation of misinformation. These automated bots that pose as human users use tactics such as tweeting and retweeting frequently, tagging accounts, and mentioning influential figures to extend their outreach. The followers of a lot of influential public figures are often bots, an analysis of Former President Trump's twitter account showed that 61% of his followers were found to be bots, spam, propaganda, or inactive accounts. While some bots are benign, when bots are used to mass produce and reiterate inaccurate content, it augments the issue of the large-scale spread of misinformation.<br><br>
            After being criticized for not doing enough to reduce the visibility of misleading information, Twitter started, in July, testing for a new feature that displays warning labels on false and misleading tweets. The feature targets 3 types of misinformation: manipulated media (media that have been altered in ways that could cause real harm), election and voting related misinformation, and misleading tweets related to Covid-19. With certain tweets, users can also click a “Learn more” label that leads them to additional information about Covid-19.</p>

            <img class="image" width="50%" src="../images/twitter.png" alt="Twitter feed">

        </div>
    </div>
    <div class="row footer">
      <p class="footerText">
          COMP 380 Introduction to Digital Culture<br>
          Christine Gao, Shruthi Gopalan, Ashley Wortham, Callie Xu, Sena Zadeh
      </p>
    </div>
  </div>


</body>
</html>